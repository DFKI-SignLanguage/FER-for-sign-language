{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db2be90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timm: 0.4.5\n",
      "Torch: 1.9.0+cu102\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras.backend import set_session \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess=tf.compat.v1.Session(config=config)\n",
    "set_session(sess)\n",
    "\n",
    "from torchvision.models import resnet101,mobilenet_v2\n",
    "import sys\n",
    "import timm\n",
    "sys.path.insert(0, 'timm==0.4.5')\n",
    "#import timm #gets version 2\n",
    "print(f\"Timm: {timm.__version__}\")\n",
    "print(f\"Torch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50dcd837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507\n",
      "507\n",
      "507\n",
      "507\n",
      "507\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "use_cuda = torch.cuda.is_available()\n",
    "batch_size=2\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_dir_1 = r'C:\\Users\\HP\\SLR\\crossVal\\Data\\fold_1_c\\test_files'\n",
    "test_dir_2 = r'C:\\Users\\HP\\SLR\\crossVal\\Data\\fold_2_c\\test_files'\n",
    "test_dir_3 = r'C:\\Users\\HP\\SLR\\crossVal\\Data\\fold_3_c\\test_files'\n",
    "test_dir_4 = r'C:\\Users\\HP\\SLR\\crossVal\\Data\\fold_4_c\\test_files'\n",
    "test_dir_5 = r'C:\\Users\\HP\\SLR\\crossVal\\Data\\fold_5_c\\test_files'\n",
    "\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "test_dataset_1 = datasets.ImageFolder(root=test_dir_1, transform=test_transforms)\n",
    "test_loader_1  = torch.utils.data.DataLoader(test_dataset_1, batch_size=batch_size, shuffle=False, **kwargs) \n",
    "\n",
    "test_dataset_2 = datasets.ImageFolder(root=test_dir_2, transform=test_transforms)\n",
    "test_loader_2  = torch.utils.data.DataLoader(test_dataset_2, batch_size=batch_size, shuffle=False, **kwargs) \n",
    "\n",
    "test_dataset_3 = datasets.ImageFolder(root=test_dir_3, transform=test_transforms)\n",
    "test_loader_3  = torch.utils.data.DataLoader(test_dataset_3, batch_size=batch_size, shuffle=False, **kwargs) \n",
    "\n",
    "test_dataset_4 = datasets.ImageFolder(root=test_dir_4, transform=test_transforms)\n",
    "test_loader_4  = torch.utils.data.DataLoader(test_dataset_4, batch_size=batch_size, shuffle=False, **kwargs) \n",
    "\n",
    "test_dataset_5 = datasets.ImageFolder(root=test_dir_5, transform=test_transforms)\n",
    "test_loader_5  = torch.utils.data.DataLoader(test_dataset_5, batch_size=batch_size, shuffle=False, **kwargs) \n",
    "\n",
    "print(len(test_dataset_1))\n",
    "print(len(test_dataset_2))\n",
    "print(len(test_dataset_3))\n",
    "print(len(test_dataset_4))\n",
    "print(len(test_dataset_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "714a0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = [test_dataset_1, test_dataset_2, test_dataset_3, test_dataset_4, test_dataset_5]\n",
    "test_dirs = [test_dir_1, test_dir_2, test_dir_3, test_dir_4, test_dir_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "314687c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): SiLU(inplace=True)\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "        (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(144, 144, kernel_size=(5, 5), stride=(2, 2), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(240, 240, kernel_size=(3, 3), stride=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(672, 672, kernel_size=(5, 5), stride=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act2): SiLU(inplace=True)\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = torch.load(r'C:\\Users\\HP\\SLR\\models\\affectnet_emotions\\enet_b0_7.pt')\n",
    "new_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e70646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = {'anger': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
    "idx_to_class = {0: 'anger', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84089d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a8cf2b729e45638e2d9801efc8b94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.14003944773175\n",
      "anger acc: 33.333333\n",
      "disgust acc: 54.545455\n",
      "fear acc: 50.000000\n",
      "happy acc: 37.500000\n",
      "neutral acc: 80.645161\n",
      "sad acc: 11.764706\n",
      "surprise acc: 63.513514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.81      0.33      0.47       144\n",
      "     Disgust       0.30      0.55      0.38        55\n",
      "        Fear       0.22      0.50      0.31        54\n",
      "       Happy       0.43      0.38      0.40        24\n",
      "     Neutral       0.46      0.81      0.59        31\n",
      "     Sadness       0.40      0.12      0.18        51\n",
      "    Surprise       0.70      0.64      0.67       148\n",
      "\n",
      "    accuracy                           0.47       507\n",
      "   macro avg       0.47      0.47      0.43       507\n",
      "weighted avg       0.58      0.47      0.48       507\n",
      "\n",
      "Fold 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73345b67b0cb4862a1474e54be3aa9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.30966469428008\n",
      "anger acc: 47.826087\n",
      "disgust acc: 50.000000\n",
      "fear acc: 10.204082\n",
      "happy acc: 56.818182\n",
      "neutral acc: 44.444444\n",
      "sad acc: 22.535211\n",
      "surprise acc: 74.509804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.83      0.48      0.61        92\n",
      "     Disgust       0.23      0.50      0.31        44\n",
      "        Fear       0.08      0.10      0.09        49\n",
      "       Happy       0.69      0.57      0.62        44\n",
      "     Neutral       0.44      0.44      0.44        54\n",
      "     Sadness       0.62      0.23      0.33        71\n",
      "    Surprise       0.63      0.75      0.68       153\n",
      "\n",
      "    accuracy                           0.49       507\n",
      "   macro avg       0.50      0.44      0.44       507\n",
      "weighted avg       0.56      0.49      0.50       507\n",
      "\n",
      "Fold 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5497c62854445e9883b6d480d98ce0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.58974358974359\n",
      "anger acc: 45.555556\n",
      "disgust acc: 58.333333\n",
      "fear acc: 31.632653\n",
      "happy acc: 68.421053\n",
      "neutral acc: 54.166667\n",
      "sad acc: 37.974684\n",
      "surprise acc: 44.295302\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.63      0.46      0.53        90\n",
      "     Disgust       0.13      0.58      0.21        24\n",
      "        Fear       0.28      0.32      0.30        98\n",
      "       Happy       0.72      0.68      0.70        19\n",
      "     Neutral       0.48      0.54      0.51        48\n",
      "     Sadness       0.79      0.38      0.51        79\n",
      "    Surprise       0.59      0.44      0.51       149\n",
      "\n",
      "    accuracy                           0.44       507\n",
      "   macro avg       0.52      0.49      0.47       507\n",
      "weighted avg       0.54      0.44      0.46       507\n",
      "\n",
      "Fold 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07e08d359644123a565394602b7fb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.90138067061144\n",
      "anger acc: 50.000000\n",
      "disgust acc: 55.172414\n",
      "fear acc: 33.802817\n",
      "happy acc: 60.416667\n",
      "neutral acc: 36.111111\n",
      "sad acc: 15.000000\n",
      "surprise acc: 65.641026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.79      0.50      0.61        68\n",
      "     Disgust       0.17      0.55      0.26        29\n",
      "        Fear       0.32      0.34      0.33        71\n",
      "       Happy       0.56      0.60      0.58        48\n",
      "     Neutral       0.26      0.36      0.30        36\n",
      "     Sadness       0.60      0.15      0.24        60\n",
      "    Surprise       0.72      0.66      0.69       195\n",
      "\n",
      "    accuracy                           0.50       507\n",
      "   macro avg       0.49      0.45      0.43       507\n",
      "weighted avg       0.58      0.50      0.51       507\n",
      "\n",
      "Fold 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3aa192d1cf1445090c5db2f02da6db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.658777120315584\n",
      "anger acc: 34.782609\n",
      "disgust acc: 60.000000\n",
      "fear acc: 25.000000\n",
      "happy acc: 43.181818\n",
      "neutral acc: 57.692308\n",
      "sad acc: 10.344828\n",
      "surprise acc: 50.609756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.58      0.35      0.43       115\n",
      "     Disgust       0.16      0.60      0.25        35\n",
      "        Fear       0.12      0.25      0.16        36\n",
      "       Happy       0.83      0.43      0.57        44\n",
      "     Neutral       0.24      0.58      0.34        26\n",
      "     Sadness       0.56      0.10      0.17        87\n",
      "    Surprise       0.66      0.51      0.57       164\n",
      "\n",
      "    accuracy                           0.39       507\n",
      "   macro avg       0.45      0.40      0.36       507\n",
      "weighted avg       0.54      0.39      0.41       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "targets = ['anger','disgust','fear','happy','neutral','sad','surprise']\n",
    "k = 1\n",
    "\n",
    "for test_dir in test_dirs:\n",
    "    \n",
    "    print('Fold ' + str(k))\n",
    "\n",
    "    device = 'cuda'\n",
    "    y_val,y_scores_val=[],[]\n",
    "    #new_model.eval()\n",
    "    for class_name in tqdm(os.listdir(test_dir)):\n",
    "        if class_name in class_to_idx:\n",
    "            class_dir=os.path.join(test_dir,class_name)\n",
    "            y=class_to_idx[class_name]\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                filepath=os.path.join(class_dir,img_name)\n",
    "                img = Image.open(filepath)\n",
    "                img_tensor = test_transforms(img)\n",
    "                img_tensor.unsqueeze_(0)\n",
    "                scores = new_model(img_tensor.to(device))\n",
    "                scores=scores[0].data.cpu().numpy()\n",
    "                #print(scores.shape)\n",
    "                y_scores_val.append(scores)\n",
    "                y_val.append(y)\n",
    "\n",
    "    y_scores_val=np.array(y_scores_val)\n",
    "    y_val=np.array(y_val)\n",
    "    #print(y_scores_val.shape,y_val.shape)\n",
    "    \n",
    "    # Accuracy & Sensitivity per class\n",
    "    y_pred=np.argmax(y_scores_val,axis=1)\n",
    "    acc=100.0*(y_val==y_pred).sum()/len(y_val)\n",
    "    print(acc)\n",
    "\n",
    "    for i in range(y_scores_val.shape[1]):\n",
    "        _val_acc=(y_pred[y_val==i]==i).sum()/(y_val==i).sum()\n",
    "        print('%s acc: %f' %(idx_to_class[i],100*_val_acc))\n",
    "        \n",
    "    \n",
    "    #Classification Report \n",
    "    target_names = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sadness', 'Surprise']\n",
    "    print(classification_report(y_val, y_pred, target_names=target_names))\n",
    "    \n",
    "    k = k + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97fb854",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef01512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 38.658777120315584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc=100.0*(y_val==y_pred).sum()/len(y_val)\n",
    "print('Accuracy:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "669a286b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40894046614331425\n"
     ]
    }
   ],
   "source": [
    "# Weighted accuracy\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "w_acc = f1_score(y_val, y_pred, average='weighted')\n",
    "print(w_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10216073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.35      0.43       115\n",
      "           1       0.16      0.60      0.25        35\n",
      "           2       0.12      0.25      0.16        36\n",
      "           3       0.83      0.43      0.57        44\n",
      "           4       0.24      0.58      0.34        26\n",
      "           5       0.56      0.10      0.17        87\n",
      "           6       0.66      0.51      0.57       164\n",
      "\n",
      "    accuracy                           0.39       507\n",
      "   macro avg       0.45      0.40      0.36       507\n",
      "weighted avg       0.54      0.39      0.41       507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clas_report = classification_report(y_val, y_pred, labels=None, target_names=None, sample_weight=None)\n",
    "print(clas_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eddbd4",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e17928db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['anger', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'])\n",
      "[[0.34782609 0.33913043 0.07826087 0.         0.11304348 0.03478261\n",
      "  0.08695652]\n",
      " [0.         0.6        0.22857143 0.11428571 0.         0.02857143\n",
      "  0.02857143]\n",
      " [0.02777778 0.41666667 0.25       0.         0.02777778 0.02777778\n",
      "  0.25      ]\n",
      " [0.02272727 0.22727273 0.         0.43181818 0.09090909 0.\n",
      "  0.22727273]\n",
      " [0.07692308 0.03846154 0.07692308 0.         0.57692308 0.\n",
      "  0.23076923]\n",
      " [0.11494253 0.43678161 0.08045977 0.         0.18390805 0.10344828\n",
      "  0.08045977]\n",
      " [0.09146341 0.05487805 0.26219512 0.         0.07926829 0.00609756\n",
      "  0.50609756]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_val, y_pred, normalize='true')\n",
    "print(idx_to_class.values())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5875f40",
   "metadata": {},
   "source": [
    "# Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85307de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49635036 0.67741935 0.36842105 0.47368421 0.47619048 0.18644068\n",
      " 0.73053892]\n"
     ]
    }
   ],
   "source": [
    "# Sensitivity per class\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "sensitivity_per_class = recall_score(y_val,y_pred,average=None)\n",
    "print(sensitivity_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5061657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity :  0.6238532110091743\n"
     ]
    }
   ],
   "source": [
    "sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "print('Sensitivity : ', sensitivity )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b5798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
